{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install bert-score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!conda install -y gdown","execution_count":8,"outputs":[{"output_type":"stream","text":"Collecting package metadata (current_repodata.json): done\nSolving environment: | ^C\nfailed with initial frozen solve. Retrying with flexible solve.\n\nCondaError: KeyboardInterrupt\n\n","name":"stdout"}]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"!gdown https://drive.google.com/uc?id=1Gms1XhLqBaTFkZPEqv_BGqL4NM-o0fmJ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!unzip tapt_data.zip","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from torch import cuda\ndevice = 'cuda' if cuda.is_available() else 'cpu'\nprint(device)\n!nvidia-smi","execution_count":9,"outputs":[{"output_type":"stream","text":"cuda\nSun Dec  6 20:17:55 2020       \n+-----------------------------------------------------------------------------+\n| NVIDIA-SMI 450.51.06    Driver Version: 450.51.06    CUDA Version: 11.0     |\n|-------------------------------+----------------------+----------------------+\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n|                               |                      |               MIG M. |\n|===============================+======================+======================|\n|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n| N/A   36C    P0    26W / 250W |      2MiB / 16280MiB |      0%      Default |\n|                               |                      |                  N/A |\n+-------------------------------+----------------------+----------------------+\n                                                                               \n+-----------------------------------------------------------------------------+\n| Processes:                                                                  |\n|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n|        ID   ID                                                   Usage      |\n|=============================================================================|\n|  No running processes found                                                 |\n+-----------------------------------------------------------------------------+\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#!pip install -q --force-reinstall transformers\n# !pip install -q --force-reinstall git+https://github.com/adapter-hub/adapter-transformers.git\n!pip install adapter-transformers\n# install datasets\n!pip install -q datasets\n\n# Make sure that we have a recent version of pyarrow in the session before we continue - otherwise reboot Colab to activate it\nimport pyarrow\nif int(pyarrow.__version__.split('.')[1]) < 16 and int(pyarrow.__version__.split('.')[0]) == 0:\n    import os\n    os.kill(os.getpid(), 9)\n\n#!git clone https://github.com/huggingface/transformers\n#!python transformers/utils/download_glue_data.py --tasks SST","execution_count":10,"outputs":[{"output_type":"stream","text":"Requirement already satisfied: adapter-transformers in /opt/conda/lib/python3.7/site-packages (1.1.0)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.7/site-packages (from adapter-transformers) (2020.4.4)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from adapter-transformers) (3.0.10)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.7/site-packages (from adapter-transformers) (20.1)\nRequirement already satisfied: sacremoses in /opt/conda/lib/python3.7/site-packages (from adapter-transformers) (0.0.43)\nRequirement already satisfied: protobuf in /opt/conda/lib/python3.7/site-packages (from adapter-transformers) (3.14.0)\nRequirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from adapter-transformers) (2.23.0)\nRequirement already satisfied: tokenizers==0.9.3 in /opt/conda/lib/python3.7/site-packages (from adapter-transformers) (0.9.3)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from adapter-transformers) (1.18.5)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.7/site-packages (from adapter-transformers) (4.45.0)\nRequirement already satisfied: sentencepiece==0.1.91 in /opt/conda/lib/python3.7/site-packages (from adapter-transformers) (0.1.91)\nRequirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging->adapter-transformers) (2.4.7)\nRequirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from packaging->adapter-transformers) (1.14.0)\nRequirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from packaging->adapter-transformers) (1.14.0)\nRequirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->adapter-transformers) (2.9)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->adapter-transformers) (2020.12.5)\nRequirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->adapter-transformers) (1.25.9)\nRequirement already satisfied: chardet<4,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests->adapter-transformers) (3.0.4)\nRequirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from packaging->adapter-transformers) (1.14.0)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.7/site-packages (from adapter-transformers) (2020.4.4)\nRequirement already satisfied: joblib in /opt/conda/lib/python3.7/site-packages (from sacremoses->adapter-transformers) (0.14.1)\nRequirement already satisfied: click in /opt/conda/lib/python3.7/site-packages (from sacremoses->adapter-transformers) (7.1.1)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.7/site-packages (from adapter-transformers) (4.45.0)\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom sklearn import metrics\nimport transformers\nimport torch\nimport dataclasses\nimport logging\nimport os\nimport sys\nfrom dataclasses import dataclass, field\nfrom typing import Dict, Optional\n\nfrom torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler\nfrom transformers import BertTokenizer, BertModel, BertConfig\nfrom transformers import RobertaTokenizer, RobertaModel\nfrom transformers import AutoTokenizer, EvalPrediction, AutoModelWithHeads, AdapterType\nfrom transformers import (\n    Trainer,\n    TrainingArguments,\n    glue_compute_metrics,\n    glue_tasks_num_labels,\n    set_seed,\n    AdapterType,CONFIG_MAPPING,\n    MODEL_WITH_LM_HEAD_MAPPING,\n    AdapterArguments,\n    AdapterConfig,\n    AdapterType,\n    AutoConfig,\n    AutoModelWithLMHead,\n    AutoTokenizer,\n    DataCollatorForLanguageModeling,\n    HfArgumentParser,\n    LineByLineTextDataset,\n    PreTrainedTokenizer,\n    TextDataset,\n    Trainer,\n    TrainingArguments\n)\n\nfrom typing import Any, Iterable, List, NewType, Optional, Tuple, Union\nimport dataclasses\nimport json\nfrom pathlib import Path\nfrom sklearn.preprocessing import LabelEncoder\nimport torch\nfrom sklearn.metrics import accuracy_score, precision_recall_fscore_support\n\nmodel_name = \"roberta-base\"\ntokenizer = AutoTokenizer.from_pretrained(model_name, max_len=512)","execution_count":11,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!curl --create-dirs -Lo ./data/citation_intent/train.jsonl https://allennlp.s3-us-west-2.amazonaws.com/dont_stop_pretraining/data/citation_intent/train.jsonl\n!curl --create-dirs -Lo ./data/citation_intent/dev.jsonl https://allennlp.s3-us-west-2.amazonaws.com/dont_stop_pretraining/data/citation_intent/dev.jsonl\n!curl --create-dirs -Lo ./data/citation_intent/test.jsonl https://allennlp.s3-us-west-2.amazonaws.com/dont_stop_pretraining/data/citation_intent/test.jsonl\n\n!curl --create-dirs -Lo ./data/sciie/train.jsonl https://allennlp.s3-us-west-2.amazonaws.com/dont_stop_pretraining/data/sciie/train.jsonl\n!curl --create-dirs -Lo ./data/sciie/dev.jsonl https://allennlp.s3-us-west-2.amazonaws.com/dont_stop_pretraining/data/sciie/dev.jsonl\n!curl --create-dirs -Lo ./data/sciie/test.jsonl https://allennlp.s3-us-west-2.amazonaws.com/dont_stop_pretraining/data/sciie/test.jsonl","execution_count":12,"outputs":[{"output_type":"stream","text":"  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                 Dload  Upload   Total   Spent    Left  Speed\n100  454k  100  454k    0     0   707k      0 --:--:-- --:--:-- --:--:--  706k\n  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                 Dload  Upload   Total   Spent    Left  Speed\n100 30138  100 30138    0     0  76298      0 --:--:-- --:--:-- --:--:-- 76298\n  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                 Dload  Upload   Total   Spent    Left  Speed\n100 38637  100 38637    0     0    98k      0 --:--:-- --:--:-- --:--:--   98k\n  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                 Dload  Upload   Total   Spent    Left  Speed\n100  804k  100  804k    0     0  1289k      0 --:--:-- --:--:-- --:--:-- 1287k\n  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                 Dload  Upload   Total   Spent    Left  Speed\n100  115k  100  115k    0     0   223k      0 --:--:-- --:--:-- --:--:--  223k\n  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                 Dload  Upload   Total   Spent    Left  Speed\n100  243k  100  243k    0     0   431k      0 --:--:-- --:--:-- --:--:--  431k\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"def getDF(filename):\n    with open(filename) as f:\n        content = f.readlines()\n    data = []\n    for t in content:\n      data.append(json.loads(t))\n    df = pd.DataFrame(data)\n    return df\n\nsampling_fraction=0.5\n\nfilename = \"data/sciie/dev.jsonl\"\nnew_df = getDF(filename).sample(frac=sampling_fraction)\n\nwith open(\"flat_sciie_dev.jsonl\", \"w\") as outfile:\n    outfile.write(\"\\n\".join(new_df[\"text\"]))\n\nfilename = \"data/sciie/test.jsonl\"\nnew_df = getDF(filename).sample(frac=sampling_fraction)\n\nwith open(\"flat_sciie_test.jsonl\", \"w\") as outfile:\n    outfile.write(\"\\n\".join(new_df[\"text\"]))\n\nfilename = \"data/sciie/train.jsonl\"\nnew_df = getDF(filename).sample(frac=sampling_fraction)\n\nwith open(\"flat_sciie_train.jsonl\", \"w\") as outfile:\n    outfile.write(\"\\n\".join(new_df[\"text\"]))\n\nfrom transformers import LineByLineTextDataset\n\ntrain_dataset = LineByLineTextDataset(\n    tokenizer=tokenizer,\n    file_path=\"flat_sciie_train.jsonl\",\n    block_size=128,\n)\n\ntest_dataset = LineByLineTextDataset(\n    tokenizer=tokenizer,\n    file_path=\"flat_sciie_test.jsonl\",\n    block_size=128,\n)\n\nval_dataset = LineByLineTextDataset(\n    tokenizer=tokenizer,\n    file_path=\"flat_sciie_dev.jsonl\",\n    block_size=128,\n)","execution_count":26,"outputs":[{"output_type":"stream","text":"/opt/conda/lib/python3.7/site-packages/transformers/data/datasets/language_modeling.py:114: FutureWarning: This dataset will be removed from the library soon, preprocessing should be handled with the 🤗 Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/master/examples/language-modeling/run_mlm.py\n  FutureWarning,\n","name":"stderr"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"language = 'tapt-pfeiffer'\n\nfrom transformers import AutoModelForMaskedLM, PfeifferConfig, HoulsbyConfig\nmodel = AutoModelForMaskedLM.from_pretrained(model_name)\ntokenizer = AutoTokenizer.from_pretrained(model_name)\nmodel.resize_token_embeddings(len(tokenizer))\nadapter_config = PfeifferConfig()\nmodel.add_adapter(language, AdapterType.text_lang, config=adapter_config)\nmodel.train_adapter([language])","execution_count":27,"outputs":[{"output_type":"stream","text":"Some weights of RobertaForMaskedLM were not initialized from the model checkpoint at roberta-base and are newly initialized: ['lm_head.decoder.bias']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","name":"stderr"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from transformers import DataCollatorForLanguageModeling\n# from datasets import load_metric\n# metric = load_metric(\"bertscore\")\n\ndata_collator = DataCollatorForLanguageModeling(\n    tokenizer=tokenizer, mlm=True, mlm_probability=0.15\n)\n\ntraining_args = TrainingArguments(\n    logging_steps=50, \n    per_device_train_batch_size=32, \n    per_device_eval_batch_size=32, \n    save_steps=130,\n    evaluate_during_training=True,\n    output_dir=\"./models/TAPT_pfeiffer\",\n    overwrite_output_dir=True,\n    do_train=True,\n    do_eval=True,\n    do_predict=True,\n    learning_rate=0.0001,\n    num_train_epochs=100,\n    save_total_limit = 1,\n    gradient_accumulation_steps = 2\n)\ntrainer = Trainer(\n      model=model,\n        args=training_args,\n        data_collator=data_collator,\n        train_dataset=train_dataset,\n        eval_dataset=val_dataset,\n    )\n\ntrainer.train()\ntrainer.evaluate()\n\n# get test results\n_, _, metrics = trainer.predict(test_dataset)\nprint(f\"Test results: \\n {metrics}\")","execution_count":28,"outputs":[{"output_type":"stream","text":"/opt/conda/lib/python3.7/site-packages/transformers/training_args.py:347: FutureWarning: The `evaluate_during_training` argument is deprecated in favor of `evaluation_strategy` (which has more options)\n  FutureWarning,\n","name":"stderr"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n        <style>\n            /* Turns off some styling */\n            progress {\n                /* gets rid of default border in Firefox and Opera. */\n                border: none;\n                /* Needs to be in here for Safari polyfill so background images work as expected. */\n                background-size: auto;\n            }\n        </style>\n      \n      <progress value='2500' max='2500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [2500/2500 26:27, Epoch 99/100]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>50</td>\n      <td>9.728006</td>\n      <td>7.027549</td>\n    </tr>\n    <tr>\n      <td>100</td>\n      <td>7.438903</td>\n      <td>5.729332</td>\n    </tr>\n    <tr>\n      <td>150</td>\n      <td>6.409431</td>\n      <td>5.549152</td>\n    </tr>\n    <tr>\n      <td>200</td>\n      <td>6.310161</td>\n      <td>5.516529</td>\n    </tr>\n    <tr>\n      <td>250</td>\n      <td>6.192893</td>\n      <td>5.344763</td>\n    </tr>\n    <tr>\n      <td>300</td>\n      <td>6.058325</td>\n      <td>5.350365</td>\n    </tr>\n    <tr>\n      <td>350</td>\n      <td>5.979995</td>\n      <td>5.177611</td>\n    </tr>\n    <tr>\n      <td>400</td>\n      <td>5.859517</td>\n      <td>5.296164</td>\n    </tr>\n    <tr>\n      <td>450</td>\n      <td>5.789614</td>\n      <td>5.187393</td>\n    </tr>\n    <tr>\n      <td>500</td>\n      <td>5.710713</td>\n      <td>5.168554</td>\n    </tr>\n    <tr>\n      <td>550</td>\n      <td>5.675703</td>\n      <td>4.856564</td>\n    </tr>\n    <tr>\n      <td>600</td>\n      <td>5.462964</td>\n      <td>4.703535</td>\n    </tr>\n    <tr>\n      <td>650</td>\n      <td>5.335220</td>\n      <td>4.696079</td>\n    </tr>\n    <tr>\n      <td>700</td>\n      <td>5.211836</td>\n      <td>4.569211</td>\n    </tr>\n    <tr>\n      <td>750</td>\n      <td>5.162695</td>\n      <td>4.474477</td>\n    </tr>\n    <tr>\n      <td>800</td>\n      <td>5.099648</td>\n      <td>4.360580</td>\n    </tr>\n    <tr>\n      <td>850</td>\n      <td>5.048193</td>\n      <td>4.363594</td>\n    </tr>\n    <tr>\n      <td>900</td>\n      <td>5.032969</td>\n      <td>4.439110</td>\n    </tr>\n    <tr>\n      <td>950</td>\n      <td>4.947998</td>\n      <td>4.437118</td>\n    </tr>\n    <tr>\n      <td>1000</td>\n      <td>4.870527</td>\n      <td>4.480388</td>\n    </tr>\n    <tr>\n      <td>1050</td>\n      <td>4.885195</td>\n      <td>4.447526</td>\n    </tr>\n    <tr>\n      <td>1100</td>\n      <td>4.818535</td>\n      <td>4.374715</td>\n    </tr>\n    <tr>\n      <td>1150</td>\n      <td>4.787920</td>\n      <td>4.411193</td>\n    </tr>\n    <tr>\n      <td>1200</td>\n      <td>4.709062</td>\n      <td>4.237473</td>\n    </tr>\n    <tr>\n      <td>1250</td>\n      <td>4.660186</td>\n      <td>4.251929</td>\n    </tr>\n    <tr>\n      <td>1300</td>\n      <td>4.676777</td>\n      <td>4.392667</td>\n    </tr>\n    <tr>\n      <td>1350</td>\n      <td>4.708848</td>\n      <td>4.299853</td>\n    </tr>\n    <tr>\n      <td>1400</td>\n      <td>4.619053</td>\n      <td>4.211798</td>\n    </tr>\n    <tr>\n      <td>1450</td>\n      <td>4.608311</td>\n      <td>4.232317</td>\n    </tr>\n    <tr>\n      <td>1500</td>\n      <td>4.627988</td>\n      <td>4.206781</td>\n    </tr>\n    <tr>\n      <td>1550</td>\n      <td>4.540801</td>\n      <td>4.283372</td>\n    </tr>\n    <tr>\n      <td>1600</td>\n      <td>4.520293</td>\n      <td>4.375218</td>\n    </tr>\n    <tr>\n      <td>1650</td>\n      <td>4.477129</td>\n      <td>4.177870</td>\n    </tr>\n    <tr>\n      <td>1700</td>\n      <td>4.495781</td>\n      <td>4.304546</td>\n    </tr>\n    <tr>\n      <td>1750</td>\n      <td>4.491836</td>\n      <td>4.086115</td>\n    </tr>\n    <tr>\n      <td>1800</td>\n      <td>4.427383</td>\n      <td>4.112648</td>\n    </tr>\n    <tr>\n      <td>1850</td>\n      <td>4.410488</td>\n      <td>4.177505</td>\n    </tr>\n    <tr>\n      <td>1900</td>\n      <td>4.449785</td>\n      <td>4.070397</td>\n    </tr>\n    <tr>\n      <td>1950</td>\n      <td>4.410176</td>\n      <td>4.201507</td>\n    </tr>\n    <tr>\n      <td>2000</td>\n      <td>4.373672</td>\n      <td>4.145884</td>\n    </tr>\n    <tr>\n      <td>2050</td>\n      <td>4.332324</td>\n      <td>4.182630</td>\n    </tr>\n    <tr>\n      <td>2100</td>\n      <td>4.356562</td>\n      <td>4.146490</td>\n    </tr>\n    <tr>\n      <td>2150</td>\n      <td>4.333867</td>\n      <td>4.109056</td>\n    </tr>\n    <tr>\n      <td>2200</td>\n      <td>4.353105</td>\n      <td>4.081468</td>\n    </tr>\n    <tr>\n      <td>2250</td>\n      <td>4.306855</td>\n      <td>4.119683</td>\n    </tr>\n    <tr>\n      <td>2300</td>\n      <td>4.306191</td>\n      <td>4.145769</td>\n    </tr>\n    <tr>\n      <td>2350</td>\n      <td>4.312109</td>\n      <td>4.139098</td>\n    </tr>\n    <tr>\n      <td>2400</td>\n      <td>4.320312</td>\n      <td>3.970736</td>\n    </tr>\n    <tr>\n      <td>2450</td>\n      <td>4.313906</td>\n      <td>4.127610</td>\n    </tr>\n    <tr>\n      <td>2500</td>\n      <td>4.268789</td>\n      <td>4.114989</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n        <style>\n            /* Turns off some styling */\n            progress {\n                /* gets rid of default border in Firefox and Opera. */\n                border: none;\n                /* Needs to be in here for Safari polyfill so background images work as expected. */\n                background-size: auto;\n            }\n        </style>\n      \n      <progress value='15' max='8' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [8/8 00:02]\n    </div>\n    "},"metadata":{}},{"output_type":"error","ename":"RuntimeError","evalue":"CUDA out of memory. Tried to allocate 6.14 GiB (GPU 0; 15.90 GiB total capacity; 7.04 GiB already allocated; 3.37 GiB free; 11.66 GiB reserved in total by PyTorch)","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-28-c7e41950679a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;31m# get test results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Test results: \\n {metrics}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, test_dataset)\u001b[0m\n\u001b[1;32m   1390\u001b[0m         \u001b[0mtest_dataloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_test_dataloader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1392\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprediction_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdescription\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Prediction\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1393\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1394\u001b[0m     def prediction_loop(\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mprediction_loop\u001b[0;34m(self, dataloader, description, prediction_loss_only)\u001b[0m\n\u001b[1;32m   1457\u001b[0m                 \u001b[0mlosses_host\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlosses\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlosses_host\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlosses_host\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlosses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1458\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlogits\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1459\u001b[0;31m                 \u001b[0mpreds_host\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogits\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpreds_host\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mnested_concat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds_host\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1460\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1461\u001b[0m                 \u001b[0mlabels_host\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlabels_host\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mnested_concat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels_host\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/transformers/trainer_pt_utils.py\u001b[0m in \u001b[0;36mnested_concat\u001b[0;34m(tensors, new_tensors, padding_index)\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnested_concat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpadding_index\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch_pad_and_concatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpadding_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnumpy_pad_and_concatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpadding_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/transformers/trainer_pt_utils.py\u001b[0m in \u001b[0;36mtorch_pad_and_concatenate\u001b[0;34m(tensor1, tensor2, padding_index)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;31m# Now let's fill the result tensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensor1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew_full\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m     \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtensor1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mtensor1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensor1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtensor1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mtensor2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensor2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 6.14 GiB (GPU 0; 15.90 GiB total capacity; 7.04 GiB already allocated; 3.37 GiB free; 11.66 GiB reserved in total by PyTorch)"]}]},{"metadata":{"trusted":true},"cell_type":"code","source":"!mkdir sciie_pfieffer_lang\nmodel.save_adapter(\"sciie_pfieffer_lang/\", \"tapt-pfeiffer\")","execution_count":29,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!ls -lh sciie_pfieffer_lang","execution_count":30,"outputs":[{"output_type":"stream","text":"total 155M\r\n-rw-r--r-- 1 root root  626 Dec  6 21:28 adapter_config.json\r\n-rw-r--r-- 1 root root  212 Dec  6 21:28 head_config.json\r\n-rw-r--r-- 1 root root 4.6M Dec  6 21:28 pytorch_adapter.bin\r\n-rw-r--r-- 1 root root 150M Dec  6 21:28 pytorch_model_head.bin\r\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"!rm -r models","execution_count":21,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!zip sciie_pfieffer_lang.zip sciie_pfieffer_lang/*","execution_count":31,"outputs":[{"output_type":"stream","text":"  adding: sciie_pfieffer_lang/adapter_config.json (deflated 56%)\n  adding: sciie_pfieffer_lang/head_config.json (deflated 34%)\n  adding: sciie_pfieffer_lang/pytorch_adapter.bin (deflated 7%)\n  adding: sciie_pfieffer_lang/pytorch_model_head.bin (deflated 41%)\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"!ls -lh","execution_count":32,"outputs":[{"output_type":"stream","text":"total 187M\r\n---------- 1 root root  263 Dec  6 20:12 __notebook_source__.ipynb\r\ndrwxr-xr-x 2 root root 4.0K Dec  6 20:49 ci_pfieffer_lang\r\n-rw-r--r-- 1 root root  94M Dec  6 20:52 ci_pfieffer_lang.zip\r\ndrwxr-x--- 4 root root 4.0K Dec  6 20:15 data\r\n-rw-r--r-- 1 root root  12K Dec  6 20:18 flat_ci_dev.jsonl\r\n-rw-r--r-- 1 root root  16K Dec  6 20:18 flat_ci_test.jsonl\r\n-rw-r--r-- 1 root root 189K Dec  6 20:18 flat_ci_train.jsonl\r\n-rw-r--r-- 1 root root  45K Dec  6 21:00 flat_sciie_dev.jsonl\r\n-rw-r--r-- 1 root root  94K Dec  6 21:00 flat_sciie_test.jsonl\r\n-rw-r--r-- 1 root root 305K Dec  6 21:00 flat_sciie_train.jsonl\r\ndrwxr-xr-x 3 root root 4.0K Dec  6 21:01 models\r\ndrwxr-xr-x 6 root root 4.0K Dec  6 21:01 runs\r\ndrwxr-xr-x 2 root root 4.0K Dec  6 21:28 sciie_pfieffer_lang\r\n-rw-r--r-- 1 root root  94M Dec  6 21:29 sciie_pfieffer_lang.zip\r\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Download Ngrok to tunnel the tensorboard port to an external port\n!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n!unzip ngrok-stable-linux-amd64.zip\n\n# Run tensorboard as well as Ngrox (for tunneling as non-blocking processes)\nimport os\nimport multiprocessing\n\n\npool = multiprocessing.Pool(processes = 10)\nresults_of_processes = [pool.apply_async(os.system, args=(cmd, ), callback = None )\n                        for cmd in [\n                        f\"tensorboard --logdir ./runs/ --host 0.0.0.0 --port 6006 &\",\n                        \"./ngrok http 6006 &\"\n                        ]]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"! curl -s http://localhost:4040/api/tunnels | python3 -c \\\n    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install bert-score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"_, _, metrics = trainer.predict(test_dataset)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}